variables:
  EXTRA_INDEX_URL: https://__token__:$GL_PKG_API_TOKEN@git.grammatech.com/api/v4/projects/1587/packages/pypi/simple

stages:
  - check-format
  - build
  - test
  - setup-repo
  - test-installers1
  - test-installers2
  - deploy
  - export

default:
  image: $DOCKER_REGISTRY/research/templates/cpp/ubuntu20
  tags: ["kubernetes"]

.conan_template: &conan_template |
  conan profile new default --detect && conan profile update settings.compiler.libcxx=libstdc++11 default
  conan remote add gitlab ${CI_API_V4_URL}/packages/conan
  conan user ci_user -r gitlab -p ${CI_JOB_TOKEN}

check-format:
  stage: check-format
  script:
    - pre-commit install-hooks
    - |+
      pre-commit run --all-files --show-diff-on-failure || ( (cat <<EOF
      ================================================================================
      If this stage fails, the formatting of your changes may be incorrect.
      To automatically format your files, install pre-commit:
          pip3 install pre-commit
          pre-commit install
      pre-commit will now automatically format any files before commit.
      To fix any misformatted files, run:
          pre-commit run --all-files
      And then commit any changes.
      More information regarding pre-commit can be found at https://pre-commit.com.

      NOTE FOR PROJECTS WITH C/C++ CODE:
      pre-commit will by default use the correct version of every formatting tool
      EXCEPT FOR clang-format. You need to ensure the version of clang-format you
      use is EXACTLY version 6.0.0. This is available in Ubuntu 18 by default.
      ================================================================================
      EOF
      ) && exit 1)

build:
  stage: build
  needs: [check-format]
  image: $DOCKER_REGISTRY/rewriting/mc-asm/llvm:13
  artifacts:
    paths:
      - build/
  script:
    - *conan_template
    - mkdir build
    - cd build
    - conan install .. --remote=gitlab
    - cmake -DCMAKE_BUILD_TYPE=RelWithDebInfo ..
    - make
    - cpack -G DEB -D CPACK_MCASM_DEBIAN_PACKAGE=lib -D CPACK_DEBIAN_PACKAGE_ARCHITECTURE=amd64
    - cpack -G DEB -D CPACK_MCASM_DEBIAN_PACKAGE=lib-dbg -D CPACK_DEBIAN_PACKAGE_ARCHITECTURE=amd64
    - cpack -G DEB -D CPACK_MCASM_DEBIAN_PACKAGE=dev -D CPACK_DEBIAN_PACKAGE_ARCHITECTURE=amd64
    - cpack -G DEB -D CPACK_MCASM_DEBIAN_PACKAGE=driver -D CPACK_DEBIAN_PACKAGE_ARCHITECTURE=amd64
    - cpack -G DEB -D CPACK_MCASM_DEBIAN_PACKAGE=driver-dbg -D CPACK_DEBIAN_PACKAGE_ARCHITECTURE=amd64

build-windows:
  stage: build
  tags: [rewriting-windows]
  artifacts:
    paths:
      - mcasm-*.whl
      - mcasm-*-win64
  script:
    - pip3 install -r requirements-dev.txt
    - mkdir build
    - cd build
    - cmd.exe /C "C:\\VS\\VC\\Auxiliary\\Build\\vcvars64.bat && conan install .." | tee /dev/null
    - cmd.exe /C "C:\\VS\\VC\\Auxiliary\\Build\\vcvars64.bat && cmake -G Ninja -DPYTHON=C:\\Python39\\python.exe -DCMAKE_BUILD_TYPE=RelWithDebInfo .." | tee /dev/null
    - cmd.exe /C "C:\\VS\\VC\\Auxiliary\\Build\\vcvars64.bat && ninja" | tee /dev/null
    - cmd.exe /C "C:\\VS\\VC\\Auxiliary\\Build\\vcvars64.bat && ninja python-wheel" | tee /dev/null
    - cmd.exe /C "C:\\VS\\VC\\Auxiliary\\Build\\vcvars64.bat && ctest -V" | tee /dev/null
    - cmd.exe /C "C:\\VS\\VC\\Auxiliary\\Build\\vcvars64.bat && C:\\PROGRA~1\\CMake\\bin\\cpack.exe -G ZIP" | tee /dev/null
    - ZIP_FILE=(mcasm-*-win64.zip)
    - BASE_DIRECTORY="${ZIP_FILE%.*}"
    - unzip $ZIP_FILE
    - cp python/dist/mcasm-*.whl ../
    - cp bin/*.pdb $BASE_DIRECTORY/bin/
    - cp -r $BASE_DIRECTORY ../

test:
  stage: test
  needs: [build]
  image: $DOCKER_REGISTRY/rewriting/mc-asm/llvm:13
  script:
    - cd build
    - ctest -V

setup-repo:
  stage: setup-repo
  needs: [build, test]
  artifacts:
    paths:
      - installers/
  script:
    - mkdir installers/
    - cp build/*.deb installers/
    - cp src/driver.cpp installers/
    - cd installers/ && dpkg-scanpackages . /dev/null > Packages

test-driver:
  stage: test-installers1
  needs: [setup-repo]
  script:
    - echo -e "\ndeb [trusted=yes] file:$(pwd)/installers/ ./\n" >> /etc/apt/sources.list
    - apt-get update -y
    - apt-get install -y mcasm-driver
    - echo "ud2" | mcasm --target x86_64-linux-gnu - | grep "0f0b"

test-driver-dbg:
  stage: test-installers1
  needs: [setup-repo]
  script:
    - 'echo -e "\ndeb [trusted=yes] file:$(pwd)/installers/ ./\n" >> /etc/apt/sources.list'
    - apt-get update -y
    - apt-get install -y mcasm-driver mcasm-driver-dbg
    - '[ -f /usr/lib/debug/.build-id/$(readelf -n /usr/bin/mcasm | grep "Build ID: " | cut -d":" -f2 | sed -E "s/ ([a-f0-9]{2,})([a-f0-9]{30,})/\1\/\2/g").debug ]'

test-dev:
  stage: test-installers1
  needs: [setup-repo]
  artifacts:
    paths:
      - test-install
  script:
    - echo -e "\ndeb [trusted=yes] file:$(pwd)/installers/ ./\n" >> /etc/apt/sources.list
    - apt-get update -y
    - apt-get install -y libmcasm-dev
    - gcc test/test_lib.c -o test-install -lmcasm
    - ./test-install

test-lib:
  stage: test-installers2
  needs: [setup-repo, test-dev]
  script:
    - echo -e "\ndeb [trusted=yes] file:$(pwd)/installers/ ./\n" >> /etc/apt/sources.list
    - apt-get update -y
    - apt-get install -y libmcasm-dev
    - ./test-install

test-lib-dbg:
  stage: test-installers1
  needs: [setup-repo]
  script:
    - 'echo -e "\ndeb [trusted=yes] file:$(pwd)/installers/ ./\n" >> /etc/apt/sources.list'
    - apt-get update -y
    - apt-get install -y libmcasm libmcasm-dbg
    - '[ -f /usr/lib/debug/.build-id/$(readelf -n /usr/lib/libmcasm.so | grep "Build ID: " | cut -d":" -f2 | sed -E "s/ ([a-f0-9]{2,})([a-f0-9]{30,})/\1\/\2/g").debug ]'

deploy:
  stage: deploy
  needs: [setup-repo, test-driver, test-dev, test-lib]
  artifacts:
    name: "$CI_COMMIT_REF_NAME-$CI_JOB_NAME"
    paths:
      - '*mcasm*.deb'
    expire_in: 1 week
  script:
    - cp installers/*.deb ./

python-wheel:
  stage: deploy
  needs: [build]
  image: $DOCKER_REGISTRY/rewriting/mc-asm/llvm:13
  artifacts:
    name: "$CI_COMMIT_REF_NAME-$CI_JOB_NAME"
    paths:
      - mcasm-*-py*-*-*.whl
    expire_in: 1 week
  script:
    - pip3 install -r requirements-dev.txt
    - make -t -C build
    - make -C build python-wheel
    - auditwheel repair build/python/dist/*.whl -w build/python/dist/wheelhouse
    - cp build/python/dist/wheelhouse/*.whl ./

# This job ensures that:
#   - Release branches never publish -dev packages, and packages
#     on release branches are never overwritten.  This behavior coincides
#     with that of the external export job, where on the public pypi, packages
#     cannot be overwritten.
#   - master therefore only ever publishes '-dev' packages
#   - The -dev package on master is always the newest version in the repository
export_internal:
  stage: export
  needs: [python-wheel, build-windows]
  image: $DOCKER_REGISTRY/rewriting/mc-asm/llvm:13
  script:
    - pip3 install -r requirements-dev.txt
    - pip3 install mcasm-*manylinux2010_x86_64.whl
    - VERSION=$(python3 -c "import mcasm; print(mcasm.__version__);")
    - if [[ "$VERSION" =~ \.dev[[:digit:]]*.*$ && "$CI_COMMIT_REF_NAME" =~ ^release-.* ]]; then exit 1; fi
    # this job is not using $CI_JOB_TOKEN because it only has read access
    # https://gitlab.com/gitlab-org/gitlab/-/issues/35067
    # this job is also not using $CI_DEPLOY_USER and $CI_DEPLOY_PASSWORD because it only has write access
    - if [[ "$CI_COMMIT_BRANCH" == "master" ]]; then
        if [[ ! "$VERSION" =~ \.dev[[:digit:]]*$ ]]; then
          echo "[ERROR] On the master branch, we must be exporting a -dev version."
          exit 1;
        fi;
        if pip3 install --extra-index-url=$EXTRA_INDEX_URL "mcasm>$VERSION" 2>/dev/null; then
          echo "[ERROR] The package version being published on master should always be >= the version in the repository.";
          exit 1;
        fi;
        ls $CI_PROJECT_DIR/*.whl | xargs python3 $CI_PROJECT_DIR/delete_remote_packages.py $GL_PKG_API_TOKEN;
      fi
    - sed "s/password = <access token>/password = $GL_PKG_API_TOKEN/" $CI_PROJECT_DIR/.pypirc > ~/.pypirc
    - python3 -m twine upload --verbose --repository repypi $CI_PROJECT_DIR/*.whl
  tags:
    - kubernetes
  rules:
    - if: '$CI_COMMIT_BRANCH == "master"'
    - if: '$CI_COMMIT_REF_NAME =~ /^release-.*/'

export_external:
  stage: export
  needs: [python-wheel, build-windows]
  image: $DOCKER_REGISTRY/rewriting/mc-asm/llvm:13
  script:
    - pip3 install -r requirements-dev.txt
    - pip3 install mcasm-*manylinux2010_x86_64.whl
    - VERSION=$(python3 -c "import mcasm; print(mcasm.__version__);")
    # Do not publish .dev versions on the public pypi
    - if [[ "$VERSION" =~ \.dev[[:digit:]]*.*$ ]]; then exit 1; fi
    - python3 -m twine upload --verbose $CI_PROJECT_DIR/*.whl -u __token__ -p $PYPI_API_KEY
  tags:
    - kubernetes
  rules:
    - if: '$CI_COMMIT_REF_NAME =~ /^release-.*/'

conan_package:
  stage: build
  image: $DOCKER_REGISTRY/rewriting/mc-asm/llvm:13
  script:
    - *conan_template
    - export CONAN_PACKAGE="mcasm/0.1@"$(echo ${CI_PROJECT_NAMESPACE}/${CI_PROJECT_NAME} | sed -e "s/\\//+/g")/stable
    - conan create --remote=gitlab . ${CONAN_PACKAGE}
    - conan upload ${CONAN_PACKAGE} --all --remote=gitlab
